{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bebd650f-5d0a-453f-9bc6-0fba7fd3ceea",
   "metadata": {},
   "source": [
    "# Pierwszy checkpoint - walidacja\n",
    "# Fake News Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74589b-6c74-436a-903a-9633685abd60",
   "metadata": {},
   "source": [
    "### Wojtek Grabias, Wiktor Wierzchowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a9064f-1175-4e2f-8c20-1dd9b199e02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>Ground Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ann Coulter Make Believes She Has ‘Gay Friend...</td>\n",
       "      <td>It s hard to believe, but Donald Trump does ha...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rating: Moody‘s verbessert Ausblick für Russla...</td>\n",
       "      <td>bankensektor Der russische Staat werde die Ban...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CAN WE ADD DIRTY MONEY ‘LAUNDERING’ To The Oba...</td>\n",
       "      <td>A member of the House Intelligence Committee i...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Republicans on Obamacare repeal: 'We're going ...</td>\n",
       "      <td>WASHINGTON (Reuters) - House of Representative...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Trump, on possible DACA deal, says border wall...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69040</th>\n",
       "      <td>69040</td>\n",
       "      <td>Burundi opposition platform boycotts new round...</td>\n",
       "      <td>NAIROBI (Reuters) - Burundi s main opposition ...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69041</th>\n",
       "      <td>69041</td>\n",
       "      <td>Hillary’s Message To Former Miss Universe Cal...</td>\n",
       "      <td>Miss Universe 1996 Alicia Machado is now an Am...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69042</th>\n",
       "      <td>69042</td>\n",
       "      <td>Cop Crashes Car And Runs Away When More Cops A...</td>\n",
       "      <td>The Daily Sheeple – by Ryan Banister \\r\\nAn aw...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69043</th>\n",
       "      <td>69043</td>\n",
       "      <td>Trump Stole An Idea From North Korean Propaga...</td>\n",
       "      <td>Jesus f*cking Christ our President* is a moron...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69044</th>\n",
       "      <td>69044</td>\n",
       "      <td>BREAKING: HILLARY CLINTON’S STATE DEPARTMENT G...</td>\n",
       "      <td>IF SHE S NOT TOAST NOW THEN WE RE IN BIGGER TR...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69045 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0               0   Ann Coulter Make Believes She Has ‘Gay Friend...   \n",
       "1               1  Rating: Moody‘s verbessert Ausblick für Russla...   \n",
       "2               2  CAN WE ADD DIRTY MONEY ‘LAUNDERING’ To The Oba...   \n",
       "3               3  Republicans on Obamacare repeal: 'We're going ...   \n",
       "4               4  Trump, on possible DACA deal, says border wall...   \n",
       "...           ...                                                ...   \n",
       "69040       69040  Burundi opposition platform boycotts new round...   \n",
       "69041       69041   Hillary’s Message To Former Miss Universe Cal...   \n",
       "69042       69042  Cop Crashes Car And Runs Away When More Cops A...   \n",
       "69043       69043   Trump Stole An Idea From North Korean Propaga...   \n",
       "69044       69044  BREAKING: HILLARY CLINTON’S STATE DEPARTMENT G...   \n",
       "\n",
       "                                                    text Ground Label  \n",
       "0      It s hard to believe, but Donald Trump does ha...         fake  \n",
       "1      bankensektor Der russische Staat werde die Ban...         fake  \n",
       "2      A member of the House Intelligence Committee i...         fake  \n",
       "3      WASHINGTON (Reuters) - House of Representative...         true  \n",
       "4      WASHINGTON (Reuters) - U.S. President Donald T...         true  \n",
       "...                                                  ...          ...  \n",
       "69040  NAIROBI (Reuters) - Burundi s main opposition ...         true  \n",
       "69041  Miss Universe 1996 Alicia Machado is now an Am...         fake  \n",
       "69042  The Daily Sheeple – by Ryan Banister \\r\\nAn aw...         fake  \n",
       "69043  Jesus f*cking Christ our President* is a moron...         fake  \n",
       "69044  IF SHE S NOT TOAST NOW THEN WE RE IN BIGGER TR...         fake  \n",
       "\n",
       "[69045 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv('original_data.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bb915b",
   "metadata": {},
   "source": [
    "#### Podział danych\n",
    "Został dokonany po wyczyszczeniu danych - odwrotnie do przyjętej poprawnej konwencji, jednak w przypadku rozważanej ramki danych, kontekst zawartości całej ramki nie wpływa na wygląd wektora wynikowego, nie traktowane jest to jako niepoprawne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da619c4a",
   "metadata": {},
   "source": [
    "#### Interpretacja języków\n",
    "Jednym z pierwszych założeń grupy prepocessującej było odrzucenie wierszy zawierające artykuły w języku innym niż angielski, co ze względu na charakter ramki danych wydaje się zupełnie zasadne (inne języki są wyłącznie fake-newsami, bądź część prawdziwych informacji jest marginalna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38c20c",
   "metadata": {},
   "source": [
    "----\n",
    "### Data Preprocessing dokonany został z wykorzystaniem poniższego zestawu funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfd90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "# funkcja odpowiedzialna za czyszczenie pojedynczego wiersza\n",
    "\n",
    "def clean_text(text, punctuation_chars):\n",
    "    # usuwamy zamianę na małe litery\n",
    "    text = text.lower()\n",
    "    # rozwinięcie skrótów\n",
    "    text = expand_contractions(text)\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', ''.join(punctuation_chars)))\n",
    "    # remove digits\n",
    "    text = text.translate(str.maketrans('', '', string.digits))\n",
    "    # remove all single characters\n",
    "    pattern = r'(^| ).( |$)'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    # remove multiple spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # remove stopwords\n",
    "    text = delete_stopwords(text)\n",
    "    # stemming\n",
    "    text = stemming(text)\n",
    "    return text\n",
    "\n",
    "# funkcja odpowiedzialna za usuwanie stopwordów\n",
    "\n",
    "def delete_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# funkcja odpowiedzialna za stemizację\n",
    "\n",
    "def stemming(text):\n",
    "    words = word_tokenize(text)\n",
    "    porter = PorterStemmer()\n",
    "    stem_words = [porter.stem(word) for word in words]\n",
    "    return ' '.join(stem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5e6ab",
   "metadata": {},
   "source": [
    "#### Poprawność funkcji  procesujących\n",
    "Powyższe kroki uważamy za zasadne i poprawne w ujęciu technicznym - funkcje przekształcają ramkę danych w sposób zgodny z założeniami."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293ff5d",
   "metadata": {},
   "source": [
    "---\n",
    "### Zastrzeżenia i propozycje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa427846",
   "metadata": {},
   "source": [
    "#### Tekst w ujęciu dosłownym\n",
    "Przedstawiona przez grupę budującą propozycja przetworzenia danych zwraca wyłącznie uwagę na jej faktyczną treść - pominięta została jakakolwiek interpunkcja, styl (formalny/nieformalny), czy użycie wielkich liter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c514c3e3",
   "metadata": {},
   "source": [
    "#### Połączenie kolumn z tytułem i treścią\n",
    "Jako grupa walidacyjna mamy zastrzeżenia co do scalenia powyższych kolumn. Z czysto praktycznego punktu widzenia, sposób, w jakim został napisany tytuł artykułu, czy też sama jego treść może wskazywać na rzetelność przedstawionej wiadomości. Proponujemy zachować podział na kolumnę z treścią i tekstem artykułu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a096372",
   "metadata": {},
   "source": [
    "#### Propozycja rozwiązań\n",
    "Powyższe problemy proponujemy rozwiązać poprzez dodanie dwóch kolumn przed obróbką tekstów:\n",
    "1. Uppercase_ratio - zawiera informacje o stosunku ilości wielkich liter do długości napisu\n",
    "2. Abbrev_ratio - zawiera informacje o stosunku skrótów typu \"i've, you're\" do długości tekstu (liczba słów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b95b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_upper_chars(string):\n",
    "    return sum(map(str.isupper, string))\n",
    "\n",
    "def upper_ratio(string):\n",
    "    return n_upper_chars(string)/len(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90242f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbreviation_counter(input_text):\n",
    "    contractions = {\n",
    "        \"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "        \"aren't\": \"are not / am not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't've\": \"cannot have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he had / he would\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he shall / he will\",\n",
    "        \"he'll've\": \"he shall have / he will have\",\n",
    "        \"he's\": \"he has / he is\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how has / how is / how does\",\n",
    "        \"i'd\": \"I had / I would\",\n",
    "        \"i'd've\": \"I would have\",\n",
    "        \"i'll\": \"I shall / I will\",\n",
    "        \"i'll've\": \"I shall have / I will have\",\n",
    "        \"i'm\": \"I am\",\n",
    "        \"i've\": \"I have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it had / it would\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it shall / it will\",\n",
    "        \"it'll've\": \"it shall have / it will have\",\n",
    "        \"it's\": \"it has / it is\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she had / she would\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she shall / she will\",\n",
    "        \"she'll've\": \"she shall have / she will have\",\n",
    "        \"she's\": \"she has / she is\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so as / so is\",\n",
    "        \"that'd\": \"that would / that had\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that has / that is\",\n",
    "        \"there'd\": \"there had / there would\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there has / there is\",\n",
    "        \"they'd\": \"they had / they would\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they shall / they will\",\n",
    "        \"they'll've\": \"they shall have / they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we had / we would\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what shall / what will\",\n",
    "        \"what'll've\": \"what shall have / what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what has / what is\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when has / when is\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where has / where is\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who shall / who will\",\n",
    "        \"who'll've\": \"who shall have / who will have\",\n",
    "        \"who's\": \"who has / who is\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why has / why is\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you had / you would\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you shall / you will\",\n",
    "        \"you'll've\": \"you shall have / you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\"\n",
    "    }\n",
    "    count = 0\n",
    "    for word in input_text.split(\" \"):\n",
    "        if re.sub(',|;', '', word).lower() in contractions:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def abbrev_ratio(input_text):\n",
    "    return abbreviation_counter(input_text)/len(input_text.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a380c7",
   "metadata": {},
   "source": [
    "#### Modyfikacje\n",
    "Zmodyfikowaliśmy funkcję clean_df, aby unormowanie tekstu nastąpiło po dodaniu wcześniejszych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d6920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "\n",
    "    df = df[['title', 'text', 'Ground Label']]\n",
    "\n",
    "    df.dropna(subset=['title'], inplace=True)\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    df = df.fillna('')\n",
    "\n",
    "    punctuation_chars = [chr(i) for i in range(sys.maxunicode)\n",
    "                         if category(chr(i)).startswith(\"P\")]\n",
    "\n",
    "    df['Uppercase_ratio'] = df['title'].apply(upper_ratio)\n",
    "    df['Abbrev_ratio'] = df['text'].apply(abbrev_ratio)\n",
    "\n",
    "    df['title'] = df['title'].map(lambda x: clean_text(x, punctuation_chars))\n",
    "    df['text'] = df['text'].map(lambda x: clean_text(x, punctuation_chars))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab64a60",
   "metadata": {},
   "source": [
    "### Wektoryzacja tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e611235",
   "metadata": {},
   "source": [
    "Po wykonaniu powyższych zmian otrzymana ramka danych jest gotowa do wektoryzacji. Zespół budowy wykorzystał metodę TF-IDF. Dla urozmaicenia, poniżej wykonaliśmy tę operację wykonując word embedding. To, które z tych podejść okaże się efektywniejsze będzie można zweryfikować na etapie budowania modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0b663d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>Ground Label</th>\n",
       "      <th>Uppercase_ratio</th>\n",
       "      <th>Abbrev_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann coulter make believ gay friend make racist...</td>\n",
       "      <td>hard believ donald trump sizabl amount support...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.227848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add dirti money launder obama billion iran ran...</td>\n",
       "      <td>member hous intellig committe accus obama admi...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>republican obamacar repeal go get done</td>\n",
       "      <td>washington reuter hous repres republican leade...</td>\n",
       "      <td>true</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump possibl daca deal say border wall would ...</td>\n",
       "      <td>washington reuter us presid donald trump said ...</td>\n",
       "      <td>true</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trump administr forc peac jame pinkerton</td>\n",
       "      <td>origin appear american conserv donald trump pl...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.144578</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66778</th>\n",
       "      <td>burundi opposit platform boycott new round pea...</td>\n",
       "      <td>nairobi reuter burundi main opposit group said...</td>\n",
       "      <td>true</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66779</th>\n",
       "      <td>hillari messag former miss univers call miss p...</td>\n",
       "      <td>miss univers alicia machado american citizen v...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66780</th>\n",
       "      <td>cop crash car run away cop arriv</td>\n",
       "      <td>daili sheepl ryan banist awardwin california s...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66781</th>\n",
       "      <td>trump stole idea north korean propaganda parod...</td>\n",
       "      <td>jesu fcking christ presid moron satisfi simpli...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66782</th>\n",
       "      <td>break hillari clinton state depart gave russia...</td>\n",
       "      <td>toast bigger troubl thought much whole thing g...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66776 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      ann coulter make believ gay friend make racist...   \n",
       "1      add dirti money launder obama billion iran ran...   \n",
       "2                 republican obamacar repeal go get done   \n",
       "3      trump possibl daca deal say border wall would ...   \n",
       "4               trump administr forc peac jame pinkerton   \n",
       "...                                                  ...   \n",
       "66778  burundi opposit platform boycott new round pea...   \n",
       "66779  hillari messag former miss univers call miss p...   \n",
       "66780                   cop crash car run away cop arriv   \n",
       "66781  trump stole idea north korean propaganda parod...   \n",
       "66782  break hillari clinton state depart gave russia...   \n",
       "\n",
       "                                                    text Ground Label  \\\n",
       "0      hard believ donald trump sizabl amount support...         fake   \n",
       "1      member hous intellig committe accus obama admi...         fake   \n",
       "2      washington reuter hous repres republican leade...         true   \n",
       "3      washington reuter us presid donald trump said ...         true   \n",
       "4      origin appear american conserv donald trump pl...         fake   \n",
       "...                                                  ...          ...   \n",
       "66778  nairobi reuter burundi main opposit group said...         true   \n",
       "66779  miss univers alicia machado american citizen v...         fake   \n",
       "66780  daili sheepl ryan banist awardwin california s...         fake   \n",
       "66781  jesu fcking christ presid moron satisfi simpli...         fake   \n",
       "66782  toast bigger troubl thought much whole thing g...         fake   \n",
       "\n",
       "       Uppercase_ratio  Abbrev_ratio  \n",
       "0             0.227848      0.000000  \n",
       "1             0.426829      0.000000  \n",
       "2             0.049180      0.000000  \n",
       "3             0.079365      0.000000  \n",
       "4             0.144578      0.000000  \n",
       "...                ...           ...  \n",
       "66778         0.027397      0.000000  \n",
       "66779         0.266667      0.000000  \n",
       "66780         0.196078      0.000000  \n",
       "66781         0.224490      0.001078  \n",
       "66782         0.817204      0.000000  \n",
       "\n",
       "[66776 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('clean_data.csv')\n",
    "df2 = df2[['title', 'text', 'Ground Label', 'Uppercase_ratio', 'Abbrev_ratio']]\n",
    "df2 = df2.dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779f1d9",
   "metadata": {},
   "source": [
    "Poniższa funkcja zwróci nam krotkę z vektorami word embedding'u dla kolumny title i text, oraz kolumnę wartości Ground Label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e914e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "\n",
    "def word_embedding(df):\n",
    "    sentences = [nltk.word_tokenize(text) for text in df] \n",
    "    model = gensim.models.Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "    vector = []\n",
    "    for text in df:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        vectors = [model.wv[word] for word in words if word in model.wv.key_to_index]\n",
    "        if len(vectors) > 0:\n",
    "            vector.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            vector.append(np.zeros(model.vector_size))\n",
    "    vector = np.array(vector)\n",
    "    return vector\n",
    "\n",
    "def label_to_num(df):\n",
    "    df['Ground Label'] = np.where(df['Ground Label'] == 'true', 1, 0)\n",
    "    return df\n",
    "    \n",
    "def vectorisation(df):\n",
    "    title = word_embedding(df['title'])\n",
    "    text = word_embedding(df['text'])\n",
    "    label = label_to_num(df)['Ground Label']\n",
    "    return (title, text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad307e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = vectorisation(df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db50d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
