{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5774b7d2",
   "metadata": {},
   "source": [
    "# Walidacja ostatecznego modelu grupy:\n",
    "### Alicja Charuza, Mateusz Gałęziewski\n",
    "###### Autorzy walidacji: Wiktor Wierzchowski, Wojciech Grabias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49f0bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f43cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training data\n",
    "x_train = pd.read_csv('train_data/tfidf_train_train.csv', index_col=[0])\n",
    "y_train = pd.read_csv('train_data/y_train_train.csv', index_col=[0])\n",
    "\n",
    "#load the test data\n",
    "x_test = pd.read_csv('train_data/tfidf_train_test.csv', index_col=[0])\n",
    "y_test = pd.read_csv('train_data/y_train_test.csv', index_col=[0])\n",
    "\n",
    "#load the validation data\n",
    "x_valid = pd.read_csv('validation_data/tfidf_test.csv', index_col=[0])\n",
    "y_valid = pd.read_csv('validation_data/y_test.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f26ac576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solving problems with index after loading data\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "x_valid = x_valid.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_valid = y_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d61b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model, x, y):\n",
    "    predict = model.predict(x)\n",
    "    print('F1 score:',f1_score(y, predict))\n",
    "    print('Accuracy:',accuracy_score(y, predict))\n",
    "    print('Recall:',recall_score(y, predict))\n",
    "    print('Precision:',precision_score(y, predict))\n",
    "    print('ROC AUC:', roc_auc_score(y, model.predict_proba(x)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a27d25a",
   "metadata": {},
   "source": [
    "## Regresja logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "deba2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "Train results:\n",
      "F1 score: 0.9456044379382079\n",
      "Accuracy: 0.9572043401830636\n",
      "Recall: 0.9306187443130118\n",
      "Precision: 0.9610806577916993\n",
      "ROC AUC: 0.9906530696099143\n",
      "\n",
      "Test results:\n",
      "F1 score: 0.9309504467912266\n",
      "Accuracy: 0.945886680342364\n",
      "Recall: 0.9140375753278979\n",
      "Precision: 0.9485010115872724\n",
      "ROC AUC: 0.9856889669027739\n"
     ]
    }
   ],
   "source": [
    "# no parameters\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(x_train, y_train.values.ravel())\n",
    "print('Logistic Regression:')\n",
    "print()\n",
    "print('Train results:')\n",
    "show_results(log_reg, x_train, y_train)\n",
    "print()\n",
    "print('Test results:')\n",
    "show_results(log_reg, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad912a07",
   "metadata": {},
   "source": [
    "Regresja logistyczna radzi sobie całkiem dobrze, dlatego też nie będziemy dobierać do niej hiperparametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41b4d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "Valid results:\n",
      "F1 score: 0.9328630809925684\n",
      "Accuracy: 0.9471989697359948\n",
      "Recall: 0.9198857284809341\n",
      "Precision: 0.9462118308419574\n",
      "ROC AUC: 0.9860358362989083\n"
     ]
    }
   ],
   "source": [
    "#WALIDACJA\n",
    "print('Logistic Regression:')\n",
    "print()\n",
    "print('Valid results:')\n",
    "show_results(log_reg, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aae36816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WALIDACJA: Mimo wszystko proponujemy optymalizację hiperparametrów\n",
    "\n",
    "# parameters = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#     'fit_intercept': [True, False],\n",
    "#     'class_weight': [None, 'balanced'],\n",
    "#     'solver': ['liblinear', 'saga']\n",
    "# }\n",
    "\n",
    "# lr = LogisticRegression()\n",
    "\n",
    "# grid_search = GridSearchCV(lr, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "# print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# # Evaluate best model on test data\n",
    "# best_model = grid_search.best_estimator_\n",
    "# print(\"Test score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valid results:\n",
    "# F1 score: 0.939248576248572\n",
    "# Accuracy: 0.9491349819541451\n",
    "# Recall: 0.9198857284809341\n",
    "# Precision: 0.92734718457194\n",
    "# ROC AUC: 0.98919348179341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametry rzeczywiście poprawiły wydajność pojedynczego modelu, jednak w ostatecznym soft-votingu\n",
    "# okazały się pogarszać model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380187b0",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1dea1cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "\n",
      "Train results:\n",
      "F1 score: 0.9999620853080569\n",
      "Accuracy: 0.9999696914590531\n",
      "Recall: 0.9999241734910524\n",
      "Precision: 1.0\n",
      "ROC AUC: 0.9999999980857692\n",
      "\n",
      "Test results:\n",
      "F1 score: 0.9155206286836934\n",
      "Accuracy: 0.9330833981750017\n",
      "Recall: 0.9085430698333924\n",
      "Precision: 0.9226061915046796\n",
      "ROC AUC: 0.9289625296194625\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "tree=DecisionTreeClassifier()  \n",
    "tree.fit(x_train,y_train.values.ravel())\n",
    "print('Decision Tree:')\n",
    "print()\n",
    "print('Train results:')\n",
    "show_results(tree, x_train, y_train)\n",
    "print()\n",
    "print('Test results:')\n",
    "show_results(tree, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "94850d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "Valid results:\n",
      "F1 score: 0.9126541857116024\n",
      "Accuracy: 0.9309029669622071\n",
      "Recall: 0.9052291640789965\n",
      "Precision: 0.9202020202020202\n",
      "ROC AUC: 0.926580639050538\n"
     ]
    }
   ],
   "source": [
    "#WALIDACJA\n",
    "print('Logistic Regression:')\n",
    "print()\n",
    "print('Valid results:')\n",
    "show_results(tree, x_valid, y_valid)a\n",
    "\n",
    "# Decision Tree stabilny względem zbioru walidacyjnego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ae37b",
   "metadata": {},
   "source": [
    "Porównując wyniki zbioru treningowego i testowego widzimy, że drzewo się przeucza. Spróbujmy dobrać hiperparametry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0551cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'max_depth': randint(low=1, high=20),\n",
    "    'min_samples_leaf': randint(low=1, high=10),\n",
    "    'min_samples_split': randint(low=2, high=10)\n",
    "}\n",
    "\n",
    "tree2 = DecisionTreeClassifier()\n",
    "search = RandomizedSearchCV(tree2, param_distributions, n_iter=100, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "search.fit(x_train, y_train)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d2d2f",
   "metadata": {},
   "source": [
    "Spróbujmy teraz użyć tych parametrów do nowego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3356854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with parameters:\n",
      "\n",
      "Train results:\n",
      "F1 score: 0.9529038076938159\n",
      "Accuracy: 0.9635994423228466\n",
      "Recall: 0.9212920837124658\n",
      "Precision: 0.9867619589052221\n",
      "ROC AUC: 0.9798236555492125\n",
      "\n",
      "Test results:\n",
      "F1 score: 0.9172845077686802\n",
      "Accuracy: 0.9364505423745604\n",
      "Recall: 0.8836169419947832\n",
      "Precision: 0.9536193029490616\n",
      "ROC AUC: 0.9417685725243212\n"
     ]
    }
   ],
   "source": [
    "tree3 = DecisionTreeClassifier(max_depth=12, min_samples_leaf=1, min_samples_split=2)\n",
    "tree3.fit(x_train, y_train)\n",
    "print('Decision Tree with parameters:')\n",
    "print()\n",
    "print('Train results:')\n",
    "show_results(tree3, x_train, y_train)\n",
    "print()\n",
    "print('Test results:')\n",
    "show_results(tree3, x_test, y_test)\n",
    "\n",
    "### WALIDACJA\n",
    "# Poniższe wyniki nie mają przełożenia w rzeczywistości, są wynikiem błędnego podstawienia.\n",
    "# W rzeczywistości wyniki na zbiorze testowym są marginalnie lepsze. Różnica względem zbioru walidacyjnego\n",
    "# jest jednak na tyle mała, że dobranie tych hiperparametrów uznajemy za prawdiłowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0f411",
   "metadata": {},
   "source": [
    "Dzięki wprowadzonym zmianom udało nam się uniknąć przeuczenia modelu i doprowadziliśmy do poprawienia wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc9c81be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "Valid results:\n",
      "F1 score: 0.9172845077686802\n",
      "Accuracy: 0.9364505423745604\n",
      "Recall: 0.8836169419947832\n",
      "Precision: 0.9536193029490616\n",
      "ROC AUC: 0.9417685725243212\n"
     ]
    }
   ],
   "source": [
    "#WALIDACJA\n",
    "print('Logistic Regression:')\n",
    "print()\n",
    "print('Valid results:')\n",
    "show_results(tree3, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "058ab180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WALIDACJA: decyzja o przeszukaniu hiperparametrów jest w pełni uzasadniona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dba6b8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c240283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "\n",
      "Train results:\n",
      "F1 score: 0.9999620853080569\n",
      "Accuracy: 0.9999696914590531\n",
      "Recall: 0.9999241734910524\n",
      "Precision: 1.0\n",
      "ROC AUC: 0.9999999942573077\n",
      "\n",
      "Test results:\n",
      "F1 score: 0.9290247377282734\n",
      "Accuracy: 0.9457130120362573\n",
      "Recall: 0.8909452241957521\n",
      "Precision: 0.9705046678392639\n",
      "ROC AUC: 0.9869592777089063\n"
     ]
    }
   ],
   "source": [
    "rand_forest=RandomForestClassifier()\n",
    "rand_forest.fit(x_train,y_train.values.ravel())\n",
    "print('Random Forest:')\n",
    "print()\n",
    "print('Train results:')\n",
    "show_results(rand_forest, x_train, y_train)\n",
    "print()\n",
    "print('Test results:')\n",
    "show_results(rand_forest, x_test, y_test)\n",
    "### WALIDACJA\n",
    "# Poniższe wyniki nie mają przełożenia w rzeczywistości, są wynikiem błędnego podstawienia.\n",
    "# W rzeczywistości wyniki na zbiorze testowym są marginalnie lepsze. Różnica względem zbioru walidacyjnego\n",
    "# jest jednak na tyle mała, że dobranie tych hiperparametrów uznajemy za prawdiłowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe784235",
   "metadata": {},
   "source": [
    "Patrząc na wyniki ponownie możemy podejrzewać, że model się przeuczył. Spróbujmy dobrać hiperparametry, aby poprawić jakość modelu. Zastosujemy do tego RandomizedSearch i crosswalidację.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d21fcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "Valid results:\n",
      "F1 score: 0.9290247377282734\n",
      "Accuracy: 0.9457130120362573\n",
      "Recall: 0.8909452241957521\n",
      "Precision: 0.9705046678392639\n",
      "ROC AUC: 0.9869592777089063\n"
     ]
    }
   ],
   "source": [
    "#WALIDACJA\n",
    "print('Logistic Regression:')\n",
    "print()\n",
    "print('Valid results:')\n",
    "show_results(rand_forest, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d06f872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WALIDACJA: nie widzimy żadnej crosswalidacji, należało zwiększyć przestrzeń hiperparametrów, to dało by większe szanse \n",
    "# na znalezienie konfiguracji unikającej przetrenowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38821fe2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 144. MiB for an array with shape (2869, 6599) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 673, in _fit_and_score\n    X_test, y_test = _safe_split(estimator, X, y, test, train)\n  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 288, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 376, in _safe_indexing\n    return _pandas_indexing(X, indices, indices_dtype, axis=axis)\n  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 218, in _pandas_indexing\n    return X.take(key, axis=axis)\n  File \"D:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 3703, in take\n    new_data = self._mgr.take(\n  File \"D:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 897, in take\n    return self.reindex_indexer(\n  File \"D:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 689, in reindex_indexer\n    new_blocks = [\n  File \"D:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 690, in <listcomp>\n    blk.take_nd(\n  File \"D:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 1139, in take_nd\n    new_values = algos.take_nd(\n  File \"D:\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py\", line 117, in take_nd\n    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n  File \"D:\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py\", line 158, in _take_nd_ndarray\n    out = np.empty(out_shape, dtype=dtype)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 144. MiB for an array with shape (2869, 6599) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15596\\3007361662.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m         evaluate_candidates(\n\u001b[0m\u001b[0;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    566\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 144. MiB for an array with shape (2869, 6599) and data type float64"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'max_depth': [10, 20, 30, 40, 50]\n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(x_train, y_train.values.ravel())\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3476efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with parameters:\n",
      "\n",
      "Train results:\n",
      "F1 score: 0.9968051118210862\n",
      "Accuracy: 0.9974540825604655\n",
      "Recall: 0.9936305732484076\n",
      "Precision: 1.0\n",
      "ROC AUC: 0.9999886581827346\n",
      "\n",
      "Test results:\n",
      "F1 score: 0.9300762569471371\n",
      "Accuracy: 0.9464064589628015\n",
      "Recall: 0.893802012172401\n",
      "Precision: 0.9694193722214738\n",
      "ROC AUC: 0.9863331152271382\n"
     ]
    }
   ],
   "source": [
    "rand_forest_2 = RandomForestClassifier(max_depth=50)\n",
    "rand_forest_2.fit(x_train, y_train.values.ravel())\n",
    "print('Random Forest with parameters:')\n",
    "print()\n",
    "print('Train results:')\n",
    "show_results(rand_forest_2, x_train, y_train)\n",
    "print()\n",
    "print('Test results:')\n",
    "show_results(rand_forest_2, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85e025fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "Valid results:\n",
      "F1 score: 0.9300762569471371\n",
      "Accuracy: 0.9464064589628015\n",
      "Recall: 0.893802012172401\n",
      "Precision: 0.9694193722214738\n",
      "ROC AUC: 0.9863331152271382\n"
     ]
    }
   ],
   "source": [
    "#WALIDACJA\n",
    "print('Logistic Regression:')\n",
    "print()\n",
    "print('Valid results:')\n",
    "show_results(rand_forest_2, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef7093",
   "metadata": {},
   "source": [
    "Jak widać nie zaszła większa poprawa w porównaniu do Random Forest bez hiperparametrów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfcfb74",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ee779",
   "metadata": {},
   "source": [
    "Ze względu na długi czas przewidywania, zdecydowaliśmy się zrezygnować z użycia Support Vector Machine w ostatecznym modelu, aby przyspieszyć jego działanie w warunkach wdrożenia. Jego wyniki można zobaczyć w drugim milestonie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b86c0",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f558a960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting:\n",
      "\n",
      "Train results:\n",
      "F1 score: 0.9688968275540714\n",
      "Accuracy: 0.9757228587015822\n",
      "Recall: 0.94601152562936\n",
      "Precision: 0.99291683247115\n",
      "ROC AUC: 0.9991194213075201\n",
      "\n",
      "Test results:\n",
      "F1 score: 0.9326291382197603\n",
      "Accuracy: 0.9481896082024865\n",
      "Recall: 0.8992671717799031\n",
      "Precision: 0.968561872909699\n",
      "ROC AUC: 0.9891303982997336\n"
     ]
    }
   ],
   "source": [
    "clf = VotingClassifier(estimators=[('1', log_reg), ('2', tree3), ('3', rand_forest_2)],voting=\"soft\")\n",
    "clf.fit(x_train, y_train.values.ravel())\n",
    "print('Voting:')\n",
    "print()\n",
    "print('Train results:')\n",
    "show_results(clf, x_train, y_train.values.ravel())\n",
    "print()\n",
    "print('Test results:')\n",
    "show_results(clf, x_test, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd0319",
   "metadata": {},
   "source": [
    "Łączac powstałe modele w VotingClassifier, uzyskaliśmy jak dotąd najlepszy rezultat na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7922590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to a file\n",
    "filename = \"fake_news_model.joblib\"\n",
    "joblib.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valid results:')\n",
    "show_results(clf, x_valid, y_valid.values.ravel())\n",
    "# Valid results:\n",
    "# F1 score: 0.92886532121\n",
    "# Accuracy: 0.94219384134103\n",
    "# Recall: 0.8922945872922\n",
    "# Precision: 0.96856187290969\n",
    "# ROC AUC: 0.9801529082095"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1e3aa",
   "metadata": {},
   "source": [
    "Spójrzmy jeszcze na predykcyjność zmiennych w uzyskanym modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a28877",
   "metadata": {},
   "source": [
    "Najpierw predykcyjność zmiennych w regreji logistycznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e48206e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 coef\n",
      "reuter      26.845257\n",
      "said        13.788396\n",
      "tuesday      5.101296\n",
      "monday       4.657351\n",
      "washington   4.401255\n",
      "...               ...\n",
      "octob       -4.443670\n",
      "novemb      -4.683527\n",
      "hillari     -6.015001\n",
      "video       -6.523562\n",
      "via        -10.466876\n",
      "\n",
      "[2869 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_log = pd.DataFrame(log_reg.coef_.transpose(), \n",
    "             x_train.columns, \n",
    "             columns=['coef'])\\\n",
    "            .sort_values(by='coef', ascending=False)\n",
    "print(df_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3410a",
   "metadata": {},
   "source": [
    "Zobaczmy 30 zmiennych najbardziej wpływających na wynik, że news jest prawdziwy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4ab4971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 coef\n",
      "reuter      26.845257\n",
      "said        13.788396\n",
      "tuesday      5.101296\n",
      "monday       4.657351\n",
      "washington   4.401255\n",
      "thursday     4.359061\n",
      "that         4.279444\n",
      "friday       3.896495\n",
      "there        3.661521\n",
      "say          3.464384\n",
      "statement    3.369799\n",
      "wednesday    3.351291\n",
      "dont         3.347890\n",
      "sunday       3.317013\n",
      "what         3.219394\n",
      "newslett     2.902446\n",
      "unfold       2.855000\n",
      "ive          2.816107\n",
      "reform       2.809625\n",
      "bbc          2.801923\n",
      "didnt        2.751802\n",
      "theyr        2.732813\n",
      "london       2.731299\n",
      "twitter      2.713188\n",
      "he           2.667622\n",
      "challeng     2.612749\n",
      "year         2.581838\n",
      "rule         2.576066\n",
      "doesnt       2.546190\n",
      "sept         2.532912\n"
     ]
    }
   ],
   "source": [
    "print(df_log.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494b8c3",
   "metadata": {},
   "source": [
    "A teraz 30 zmiennych najbardziej wpływających na wynik, że news jest fałszywy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b40c3a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                coef\n",
      "post       -2.246348\n",
      "cop        -2.247017\n",
      "tell       -2.252402\n",
      "american   -2.295933\n",
      "alien      -2.331644\n",
      "fbi        -2.359544\n",
      "howev      -2.400975\n",
      "hate       -2.491655\n",
      "claim      -2.549968\n",
      "obama      -2.579420\n",
      "know       -2.599704\n",
      "fact       -2.604193\n",
      "dc         -2.611073\n",
      "lie        -2.669494\n",
      "even       -2.697838\n",
      "breitbart  -2.773025\n",
      "rep        -2.977652\n",
      "entir      -3.070840\n",
      "break      -3.082026\n",
      "news       -3.269313\n",
      "imag       -3.274048\n",
      "daili      -3.371778\n",
      "articl     -3.399443\n",
      "go         -3.435409\n",
      "wire       -4.183500\n",
      "octob      -4.443670\n",
      "novemb     -4.683527\n",
      "hillari    -6.015001\n",
      "video      -6.523562\n",
      "via       -10.466876\n"
     ]
    }
   ],
   "source": [
    "print(df_log.tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cea329",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WALIDACJA:\n",
    "# Istotną częścią każdego modelu jest jego predykcyjność,\n",
    "# Doceniamy uwzględnienie tych wpływających pozytywnie i negatywnie na \n",
    "# Ostateczną klasyfikację"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
