{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datetime import datetime\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "np.random.seed(29)\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datetime import datetime\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(29)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54615f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie Danych\n",
    "df = pd.read_csv('train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcje pomocnicze\n",
    "def zamiana_typów_kolumn_na_numeryczne(df):\n",
    "    df['Outstanding_Debt'] = Object_to_Numeric(df, 'Outstanding_Debt')\n",
    "    df['Amount_invested_monthly'] = Object_to_Numeric(df, 'Amount_invested_monthly')\n",
    "    df['Changed_Credit_Limit'] = Object_to_Numeric(df, 'Changed_Credit_Limit')\n",
    "    df['Monthly_Balance'] = df['Monthly_Balance'].str.replace('_', '')\n",
    "    df = df.astype({'Monthly_Balance': 'float'})\n",
    "    df['Credit_History_Age'] = History_Age_2_months(df)\n",
    "    df['Credit_History_Age'].loc[df.Credit_History_Age.isnull()] = df['Credit_History_Age'].loc[df.Credit_History_Age.isnull()].apply(\n",
    "          lambda x: '-1') #Brak danych jest teraz -1 \n",
    "    df['Credit_History_Age'] = df['Credit_History_Age'].apply(eval)\n",
    "    df['Payment_Behaviour'] = np.where(df['Payment_Behaviour']== '!@9#%8', np.nan, df['Payment_Behaviour'])\n",
    "    df['spent'] = np.where('Low' == df['Payment_Behaviour'].str[0:3], 0,1)\n",
    "    #2 Month na numeric\n",
    "    df['Month'] = df['Month'].apply(lambda mname: datetime.strptime(mname, '%B').month)\n",
    "\n",
    "    #4 Age na numeric\n",
    "    df['Age'] = df['Age'].convert_dtypes().apply(lambda x: x.replace(\"_\", \"\")).astype(int)\n",
    "\n",
    "    #7 Annual_Income na numeric\n",
    "    df['Annual_Income'] = df['Annual_Income'].convert_dtypes().apply(lambda x: x.replace(\"_\", \"\")).astype(float)\n",
    "\n",
    "    #12 Num_of_Loan na numeric\n",
    "    df['Num_of_Loan'] = df['Num_of_Loan'].convert_dtypes().apply(lambda x: x.replace(\"_\", \"\")).astype(int)\n",
    "\n",
    "    #15 Num_of_Delayed_Payment na numeric\n",
    "    df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].convert_dtypes()\n",
    "    df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].str.replace('_', '')\n",
    "    df['Num_of_Delayed_Payment'] = pd.to_numeric(df['Num_of_Delayed_Payment'])\n",
    "\n",
    "    df['payment_value'] = df['Payment_Behaviour'].str.extract(r'^(?:[^_]+_){2}([^_ ]+)')\n",
    "    df['payment_value'] = df['payment_value'].replace('Small', 0)\n",
    "    df['payment_value'] = df['payment_value'].replace('Medium', 1)\n",
    "    df['payment_value'] = df['payment_value'].replace('Large', 2)\n",
    "\n",
    "    df = df.drop('Payment_Behaviour', axis=1)\n",
    "\n",
    "    # __ część z one_hot ___\n",
    "    # Type_of_Loan\n",
    "    df['Type_of_Loan'] = df['Type_of_Loan'].str.replace('and ', '')\n",
    "    df.Type_of_Loan = df.Type_of_Loan.str.split(', ')\n",
    "    df['Type_of_Loan'].loc[df.Type_of_Loan.isnull()] = df['Type_of_Loan'].loc[df.Type_of_Loan.isnull()].apply(lambda x: [])\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    df = df.join(\n",
    "        pd.DataFrame.sparse.from_spmatrix(\n",
    "            mlb.fit_transform(df.pop('Type_of_Loan')),\n",
    "            index=df.index,\n",
    "            columns=mlb.classes_))\n",
    "    \n",
    "    # Credit_Mix i Occupation\n",
    "    one_hot_encoded = pd.get_dummies(df['Credit_Mix'], prefix='Credit_Mix')\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "    one_hot_encoded = pd.get_dummies(df['Occupation'], prefix='Occupation')\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "    #Payment_of_Min_Amount\n",
    "    grouped = df.groupby('Customer_ID', group_keys=False)\n",
    "    df[['Payment_of_Min_Amount']] = grouped[['Payment_of_Min_Amount']].apply(lambda x: x.fillna(x.mode()))\n",
    "    df['Payment_of_Min_Amount'].fillna(df['Payment_of_Min_Amount'].mode()[0])\n",
    "    one_hot_encoded = pd.get_dummies(df['Payment_of_Min_Amount'], prefix='Payment_of_Min_Amount')\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "    \n",
    "    df.drop(columns=['ID','SSN','Name'], inplace=True) #SSN to be removed\n",
    "    df.drop(columns=['Payment_of_Min_Amount', 'Credit_Mix', 'Occupation', 'Payment_of_Min_Amount'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def History_Age_2_months(df):\n",
    "      df['Credit_History_Age'] = df['Credit_History_Age'].str.replace(' Months', '')\n",
    "      return df['Credit_History_Age'].str.replace('\\D+', '* 12 +')\n",
    "\n",
    "def Object_to_Numeric(df, s):\n",
    "    return pd.to_numeric(df[s].str.replace('_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d35484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "\n",
    "  def Zamiana_nan_na_medianę_modę(df):\n",
    "\n",
    "    # Zamiana na NaN, a nie usunięcie rekordu\n",
    "    df.Monthly_Balance = np.where(df.Monthly_Balance == min(df.Monthly_Balance), np.nan, df.Monthly_Balance)\n",
    "    grouped = df.groupby('Customer_ID', group_keys=False)\n",
    "\n",
    "    # Zamiana NaN na medianę dla danej grupy (Grupa = zbiór rekordów danego użytkownika, identyfikowany przez jego SSN)\n",
    "    df[['Monthly_Inhand_Salary']] = grouped[['Monthly_Inhand_Salary']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Num_Bank_Accounts']] = grouped[['Num_Bank_Accounts']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Num_of_Delayed_Payment']] = grouped[['Num_of_Delayed_Payment']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Changed_Credit_Limit']] = grouped[['Changed_Credit_Limit']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Num_Credit_Inquiries']] = grouped[['Num_Credit_Inquiries']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Monthly_Balance']] = grouped[['Monthly_Balance']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Amount_invested_monthly']] = grouped[['Amount_invested_monthly']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['payment_value']] = grouped[['payment_value']].apply(lambda x: x.fillna(x.mode()))\n",
    "\n",
    "    df['Num_Bank_Accounts'].fillna(df['Num_Bank_Accounts'].median(), inplace=True) \n",
    "    df['Num_of_Delayed_Payment'].fillna(df['Num_of_Delayed_Payment'].median(), inplace=True) \n",
    "    df['Num_Bank_Accounts'].fillna(df['Num_Bank_Accounts'].median(), inplace=True) \n",
    "    df['Changed_Credit_Limit'].fillna(df['Changed_Credit_Limit'].median(), inplace=True) \n",
    "    df['Num_Credit_Inquiries'].fillna(df['Num_Credit_Inquiries'].median(), inplace=True) \n",
    "    df['Monthly_Inhand_Salary'].fillna(df['Monthly_Inhand_Salary'].median(), inplace=True) \n",
    "    df['Monthly_Balance'].fillna(df['Monthly_Balance'].median(), inplace=True) \n",
    "    df['payment_value'].fillna(df['payment_value'].mode()[0], inplace=True) \n",
    "    df['Amount_invested_monthly'].fillna(df['Amount_invested_monthly'].median(), inplace=True)\n",
    "    return df\n",
    "  \n",
    "  df = zamiana_typów_kolumn_na_numeryczne(df)\n",
    "  df = Zamiana_nan_na_medianę_modę(df)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b94f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dzielimy zbiór danych \n",
    "\n",
    "X_TRAIN, X_valid = train_test_split(df, test_size=0.30, random_state=42)\n",
    "y_valid = X_valid['Credit_Score']\n",
    "\n",
    "target = X_TRAIN['Credit_Score']\n",
    "X_train, X_test=train_test_split(\n",
    "    X_TRAIN, # X\n",
    "    test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2daba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = zamiana_typów_kolumn_na_numeryczne(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uzupełnienie braków dancych w X_test na podstawie informacji w X_train\n",
    "\n",
    "grouped = X_train.groupby('Customer_ID', group_keys=False)\n",
    "grouped2 = X_test.groupby('Customer_ID', group_keys=False)\n",
    "\n",
    "col_names = ['Monthly_Inhand_Salary','Num_Bank_Accounts','Num_of_Delayed_Payment','Changed_Credit_Limit','Num_Credit_Inquiries','Monthly_Balance',\n",
    "             'Amount_invested_monthly']\n",
    "\n",
    "for col_name in col_names:\n",
    "  new_table = np.array([]) \n",
    "  for key, item in grouped2:\n",
    "    if key in grouped.groups.keys():\n",
    "      if not math.isnan(grouped[[col_name]].get_group(key).median()[0]):\n",
    "        item[col_name].fillna(grouped[[col_name]].get_group(key).median()[0], inplace=True)\n",
    "        item1 = item.copy()\n",
    "        if new_table.shape[0]==0:\n",
    "            new_table = item1\n",
    "        else:\n",
    "            new_table = pd.concat([new_table,item1])\n",
    "      else:\n",
    "        item.fillna(X_train[col_name].median(), inplace=True)\n",
    "        item1 = item.copy()\n",
    "        if new_table.shape[0]==0:\n",
    "            new_table = item1\n",
    "        else:\n",
    "            new_table = pd.concat([new_table,item1])\n",
    "    else:\n",
    "      item.fillna(X_train[col_name].median(), inplace=True)\n",
    "      item1 = item.copy()\n",
    "      if new_table.shape[0]==0:\n",
    "          new_table = item1\n",
    "      else:\n",
    "          new_table = pd.concat([new_table,item1])\n",
    "  temp = new_table.copy()\n",
    "  X_train[col_name] = temp[col_name]\n",
    "\n",
    "\n",
    "new_table = np.array([]) \n",
    "for key, item in grouped2:\n",
    "  if key in grouped.groups.keys():\n",
    "    if not math.isnan(grouped[['payment_value']].get_group(key).mode()[0]):\n",
    "      item['payment_value'].fillna(grouped[['payment_value']].get_group(key).mode()[0], inplace=True)\n",
    "      item1 = item.copy()\n",
    "      if new_table.shape[0]==0:\n",
    "          new_table = item1\n",
    "      else:\n",
    "          new_table = pd.concat([new_table,item1])\n",
    "    else:\n",
    "      item.fillna(X_train['payment_value'].mode(), inplace=True)\n",
    "      item1 = item.copy()\n",
    "      if new_table.shape[0]==0:\n",
    "          new_table = item1\n",
    "      else:\n",
    "          new_table = pd.concat([new_table,item1])\n",
    "  else:\n",
    "    item.fillna(X_train['payment_value'].mode(), inplace=True)\n",
    "    item1 = item.copy()\n",
    "    if new_table.shape[0]==0:\n",
    "        new_table = item1\n",
    "    else:\n",
    "        new_table = pd.concat([new_table,item1])\n",
    "X_train['payment_value'] = temp['payment_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y_test = X_test['Credit_Score']\n",
    "X_test.drop(columns=['Credit_Score', 'Customer_ID'], inplace=True)\n",
    "\n",
    "y_train = X_train['Credit_Score']\n",
    "X_train.drop(columns=['Credit_Score', 'Customer_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90846b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minmax Scaler i Outliery\n",
    "# Każda kolumna traktowana oddzielnie, jednak poziom odcięcia zbioru testowego bezpośrednio przenoszona jest \n",
    "# ze zbioru treningowego, podobnie jak wartości minimalne/maksymalne przy minmax scalerze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab45f32",
   "metadata": {
    "id": "Sdw2E3JrO5Tt"
   },
   "outputs": [],
   "source": [
    "# Definiujemy nasz własny min_max scaler, by wartości min/max pochodziły ze\n",
    "# zbioru treningowego.\n",
    "def scale_mm(x_train, x_test):\n",
    "  x_train_std = (x_train - x_train.min(axis=0)) / (x_train.max(axis=0) - x_train.min(axis=0))\n",
    "  x_test_std = (x_test - x_train.min(axis=0)) / (x_train.max(axis=0) - x_train.min(axis=0))\n",
    "  return x_train_std, x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0970a3",
   "metadata": {
    "id": "QOCnhiHsN3KA"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Annual_Income.quantile(.99)\n",
    "\n",
    "X_train.Annual_Income = np.where(X_train.Annual_Income > upper_lim, upper_lim, X_train.Annual_Income)\n",
    "X_test.Annual_Income = np.where(X_test.Annual_Income > upper_lim, upper_lim, X_test.Annual_Income)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42878573",
   "metadata": {
    "id": "x6HsJKFROn3P"
   },
   "outputs": [],
   "source": [
    "X_train.Annual_Income, X_test.Annual_Income = scale_mm(X_train.Annual_Income, X_test.Annual_Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14add92a",
   "metadata": {
    "id": "0X5D0pfDQJgT"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Amount_invested_monthly.quantile(.98)\n",
    "\n",
    "X_train.Amount_invested_monthly = np.where(X_train.Amount_invested_monthly > upper_lim, upper_lim, X_train.Amount_invested_monthly)\n",
    "X_test.Amount_invested_monthly = np.where(X_test.Amount_invested_monthly > upper_lim, upper_lim, X_test.Amount_invested_monthly)\n",
    "\n",
    "X_train.Amount_invested_monthly = np.log1p(X_train.Amount_invested_monthly)\n",
    "X_test.Amount_invested_monthly = np.log1p(X_test.Amount_invested_monthly)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd50704",
   "metadata": {
    "id": "uNzHy9_sQi6m"
   },
   "outputs": [],
   "source": [
    "X_train.Amount_invested_monthly, X_test.Amount_invested_monthly = scale_mm(X_train.Amount_invested_monthly, X_test.Amount_invested_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b3c5e",
   "metadata": {
    "id": "9bKX0leLS3Hm"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Total_EMI_per_month.quantile(.96)\n",
    "\n",
    "X_train.Total_EMI_per_month = np.where(X_train.Total_EMI_per_month > upper_lim, upper_lim, X_train.Total_EMI_per_month)\n",
    "X_test.Total_EMI_per_month = np.where(X_test.Total_EMI_per_month > upper_lim, upper_lim, X_test.Total_EMI_per_month)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "X_train.Total_EMI_per_month = np.log1p(X_train.Total_EMI_per_month)\n",
    "X_test.Total_EMI_per_month = np.log1p(X_test.Total_EMI_per_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea1849",
   "metadata": {
    "id": "KdHPv8-2TF6O"
   },
   "outputs": [],
   "source": [
    "X_train.Credit_Utilization_Ratio, X_test.Credit_Utilization_Ratio = scale_mm(X_train.Credit_Utilization_Ratio, X_test.Credit_Utilization_Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7d619",
   "metadata": {
    "id": "xD6PRslvTNNJ"
   },
   "outputs": [],
   "source": [
    "X_train.Outstanding_Debt, X_test.Outstanding_Debt = scale_mm(X_train.Outstanding_Debt, X_test.Outstanding_Debt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31144c28",
   "metadata": {
    "id": "B8fbQDPbTV0K"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_Credit_Inquiries.quantile(.96)\n",
    "\n",
    "X_train.Num_Credit_Inquiries = np.where(X_train.Num_Credit_Inquiries > upper_lim, upper_lim, X_train.Num_Credit_Inquiries)\n",
    "X_test.Num_Credit_Inquiries = np.where(X_test.Num_Credit_Inquiries > upper_lim, upper_lim, X_test.Num_Credit_Inquiries)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562cd96",
   "metadata": {
    "id": "mkkvneblTf5T"
   },
   "outputs": [],
   "source": [
    "X_train.Changed_Credit_Limit, X_test.Changed_Credit_Limit = scale_mm(X_train.Changed_Credit_Limit, X_test.Changed_Credit_Limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009bfd4",
   "metadata": {
    "id": "PDOgsFLLTqLD"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Age.quantile(.98)\n",
    "lower_lim = X_train.Age.quantile(.05)\n",
    "\n",
    "X_train.Age = np.where(X_train.Age > upper_lim, upper_lim, X_train.Age)\n",
    "X_test.Age = np.where(X_test.Age > upper_lim, upper_lim, X_test.Age)\n",
    "\n",
    "X_train.Age = np.where(X_train.Age < lower_lim, lower_lim, X_train.Age)\n",
    "X_test.Age = np.where(X_test.Age < lower_lim, lower_lim, X_test.Age)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752d468",
   "metadata": {
    "id": "C7mKYbaZUDXT"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_Bank_Accounts.quantile(.98)\n",
    "lower_lim = X_train.Num_Bank_Accounts.quantile(.00)\n",
    "\n",
    "X_train.Num_Bank_Accounts = np.where(X_train.Num_Bank_Accounts > upper_lim, upper_lim, X_train.Num_Bank_Accounts)\n",
    "X_test.Num_Bank_Accounts = np.where(X_test.Num_Bank_Accounts > upper_lim, upper_lim, X_test.Num_Bank_Accounts)\n",
    "\n",
    "X_train.Num_Bank_Accounts = np.where(X_train.Num_Bank_Accounts < lower_lim, lower_lim, X_train.Num_Bank_Accounts)\n",
    "X_test.Num_Bank_Accounts = np.where(X_test.Num_Bank_Accounts < lower_lim, lower_lim, X_test.Num_Bank_Accounts)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba47170",
   "metadata": {
    "id": "fsWKMO64UQM4"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_Credit_Card.quantile(.97)\n",
    "lower_lim = X_train.Num_Credit_Card.quantile(.00)\n",
    "\n",
    "X_train.Num_Credit_Card = np.where(X_train.Num_Credit_Card > upper_lim, upper_lim, X_train.Num_Credit_Card)\n",
    "X_test.Num_Credit_Card = np.where(X_test.Num_Credit_Card > upper_lim, upper_lim, X_test.Num_Credit_Card)\n",
    "\n",
    "X_train.Num_Credit_Card = np.where(X_train.Num_Credit_Card < lower_lim, lower_lim, X_train.Num_Credit_Card)\n",
    "X_test.Num_Credit_Card = np.where(X_test.Num_Credit_Card < lower_lim, lower_lim, X_test.Num_Credit_Card)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b6d62",
   "metadata": {
    "id": "R5nh7F5LUaCl"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Interest_Rate.quantile(.97)\n",
    "\n",
    "X_train.Interest_Rate = np.where(X_train.Interest_Rate > upper_lim, upper_lim, X_train.Interest_Rate)\n",
    "X_test.Interest_Rate = np.where(X_test.Interest_Rate > upper_lim, upper_lim, X_test.Interest_Rate)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d2706",
   "metadata": {
    "id": "wxqrjkUHUhBy"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_of_Loan.quantile(.99)\n",
    "lower_lim = X_train.Num_of_Loan.quantile(.04)\n",
    "X_train.Num_of_Loan = np.where(X_train.Num_of_Loan > upper_lim, upper_lim, X_train.Num_of_Loan)\n",
    "X_test.Num_of_Loan = np.where(X_test.Num_of_Loan > upper_lim, upper_lim, X_test.Num_of_Loan)\n",
    "\n",
    "X_train.Num_of_Loan = np.where(X_train.Num_of_Loan < lower_lim, lower_lim, X_train.Num_of_Loan)\n",
    "X_test.Num_of_Loan = np.where(X_test.Num_of_Loan < lower_lim, lower_lim, X_test.Num_of_Loan)\n",
    "\n",
    "X_train =X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf34e62",
   "metadata": {
    "id": "jE1OPMrvUtaX"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Delay_from_due_date.quantile(.99)\n",
    "\n",
    "X_train.Delay_from_due_date = np.where(X_train.Delay_from_due_date > upper_lim, upper_lim, X_train.Delay_from_due_date)\n",
    "X_test.Delay_from_due_date = np.where(X_test.Delay_from_due_date > upper_lim, upper_lim, X_test.Delay_from_due_date)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1812ac9",
   "metadata": {
    "id": "NxpZBYaIUz7t"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_of_Delayed_Payment.quantile(.99)\n",
    "lower_lim = X_train.Num_of_Delayed_Payment.quantile(.01)\n",
    "\n",
    "X_train.Num_of_Delayed_Payment = np.where(X_train.Num_of_Delayed_Payment > upper_lim, upper_lim, X_train.Num_of_Delayed_Payment)\n",
    "X_test.Num_of_Delayed_Payment = np.where(X_test.Num_of_Delayed_Payment > upper_lim, upper_lim, X_test.Num_of_Delayed_Payment)\n",
    "\n",
    "X_train.Num_of_Delayed_Payment = np.where(X_train.Num_of_Delayed_Payment < lower_lim, upper_lim, X_train.Num_of_Delayed_Payment)\n",
    "X_test.Num_of_Delayed_Payment = np.where(X_test.Num_of_Delayed_Payment < lower_lim, upper_lim, X_test.Num_of_Delayed_Payment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e5f82",
   "metadata": {
    "id": "9ZOnBn7xVFzf"
   },
   "outputs": [],
   "source": [
    "# Usunięcie kolumn na podstawie korelacji spearmana (>90)\n",
    "X_train = X_train.drop(columns=['Monthly_Inhand_Salary', 'Month'])\n",
    "X_test = X_test.drop(columns=['Monthly_Inhand_Salary', 'Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048c5a9",
   "metadata": {
    "id": "Uj6emXN9V5L5"
   },
   "outputs": [],
   "source": [
    "y_test = y_test.replace('Good', 2)\n",
    "y_test = y_test.replace('Standard', 1)\n",
    "y_test = y_test.replace('Poor', 0)\n",
    "\n",
    "y_train = y_train.replace('Good', 2)\n",
    "y_train = y_train.replace('Standard', 1)\n",
    "y_train = y_train.replace('Poor', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce485a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# budowa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca5508",
   "metadata": {
    "id": "5f4dXlejbb_6"
   },
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    \n",
    "    models = dict()\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=1000, # Ilość słabych estymatorów\n",
    "                                      max_depth=2, # Maksymalna wysokość drzewa w słabym estymatorze\n",
    "                                      min_samples_split = 2, # Minimalna ilość obserwacji wymagana do podziału węzła\n",
    "                                      max_features = 3, # Maksymalna ilość zmiennych brana pod uwagę przy podziale węzła\n",
    "                                      random_state=0,\n",
    "                                      n_jobs = -1)\n",
    "    \n",
    "    models['aboost'] = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "    models['gboost'] = GradientBoostingClassifier(random_state=1,\n",
    "                                      learning_rate=0.01)\n",
    "    \n",
    "    models['xgb'] = XGBClassifier(random_state=1,\n",
    "                        learning_rate=0.01, # Szybkość \"uczenia\" się\n",
    "                        booster='gbtree', # Jaki model wykorzystujemy (drzewo - gbtree, liniowe - gblinear)\n",
    "                        max_depth=4 # Maksymalna głębokość drzewa \n",
    "                        )\n",
    "    \n",
    "    models['svm'] = SVC()\n",
    "\n",
    "    models['bayes'] = GaussianNB()\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e943a9",
   "metadata": {
    "id": "A6vGOoPfb2Rz"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f08107",
   "metadata": {
    "id": "PP9NvUENb3iI"
   },
   "outputs": [],
   "source": [
    "# modele do evaluacji\n",
    "models = get_models()\n",
    "# ocena modeli\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X_train, y_train)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('%8s mean-%.3f std-%.3f' % (name, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzam feature importance\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=1)\n",
    "feature_names = X_train.columns.values\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwam najmniej ważne kolumny\n",
    "\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "feature_names = X_train.columns.values\n",
    "\n",
    "suma = 0\n",
    "\n",
    "for i in indices:\n",
    "    print(f\"{feature_names[i]}: {importances[i]}\")\n",
    "    suma += importances[i]\n",
    "    print(\"sum:\", suma)\n",
    "    if suma < 0.1:\n",
    "        X_train.drop(columns=[feature_names[i]], inplace=True)\n",
    "        X_test.drop(columns=[feature_names[i]], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095d0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwam kolumny nieproporcjonalnie ważne\n",
    "\n",
    "X_train.drop(columns=['Credit_Mix_Good', 'Credit_Mix_Standard'], inplace=True)\n",
    "X_test.drop(columns=['Credit_Mix_Good', 'Credit_Mix_Standard'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b8b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wcześniejsza ewaluacja skuteczności modeli wskazała na hierarchie: xgb > cart > aboost > bayes\n",
    "# cart wcześniej zoptymalizowany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bab3c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiuje siatki do przeszukania\n",
    "param_grid_xgb = {'learning_rate': [0.01, 0.1, 0.5],\n",
    "                  'max_depth': [3, 5, 7],\n",
    "                  'n_estimators': [50, 200, 400],\n",
    "                 'subsample': [0.6, 0.8, 1.0],\n",
    "                 'colsample_bytree': [0.6, 0.8, 1.0]}\n",
    "\n",
    "param_grid_aboost = {'learning_rate': [0.01, 0.1, 0.5],\n",
    "                     'n_estimators': [50, 100, 200]}\n",
    "\n",
    "param_grid_bayes = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "aboost = AdaBoostClassifier()\n",
    "bayes = GaussianNB()\n",
    "\n",
    "grid_search_xgb = GridSearchCV(xgb, param_grid_xgb, cv=5, scoring='accuracy', verbose = 2)\n",
    "grid_search_aboost = GridSearchCV(aboost, param_grid_aboost, cv=5, scoring='accuracy', verbose = 2)\n",
    "grid_search_bayes = GridSearchCV(bayes, param_grid_bayes, cv=5, scoring='accuracy', verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "676fcb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykonuje grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f82036",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_aboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f655770",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estim = grid_search_xgb.best_estimator_\n",
    "y_pred_xgb = xgb_estim.predict(X_test)\n",
    "# Accuracy: 0.7691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost_estim = grid_search_aboost.best_estimator_\n",
    "y_pred_aboost = aboost_estim.predict(X_test)\n",
    "# Accuracy: 0.6647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_estim = grid_search_bayes.best_estimator_\n",
    "y_pred_bayes = bayes_estim.predict(X_test)\n",
    "# Accuracy: 0.5317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7087b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przedstawienie najlepszego osiągniętego votingu\n",
    "\n",
    "xgb_best = XGBClassifier(colsample_bytree= 0.6, \n",
    "                         learning_rate= 0.5, \n",
    "                         max_depth= 7, \n",
    "                         n_estimators= 200, \n",
    "                         subsample= 1.0)\n",
    "\n",
    "aboost_best = AdaBoostClassifier(learning_rate = 0.5,\n",
    "                                n_estimators = 200)\n",
    "\n",
    "breaker = DecisionTreeClassifier(random_state = 1,\n",
    "                                criterion='entropy',\n",
    "                                max_depth=6,\n",
    "                                min_samples_leaf=2,\n",
    "                                min_samples_split=2)\n",
    "\n",
    "estimators = [('xgb', xgb_best), ('aboost', aboost_best), ('breaker', breaker)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_vote = VotingClassifier(estimators=estimators, voting='hard')\n",
    "hard_vote.fit(X_train, y_train)\n",
    "y_pred = hard_vote.predict(X_test)\n",
    "# Accuracy: 0.7098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b181a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# najlepszy zawodnik\n",
    "level0 = list()\n",
    "level0.append(('xgb1', XGBClassifier(max_depth=7, n_estimators=500)))\n",
    "level0.append(('xgb2', XGBClassifier()))\n",
    "level0.append(('cart', DecisionTreeClassifier(random_state=1,\n",
    "                                              criterion='entropy',\n",
    "                                              max_depth=6,\n",
    "                                              min_samples_leaf=2,\n",
    "                                              min_samples_split=2)))\n",
    "level0.append(('cart2', DecisionTreeClassifier(random_state=1,\n",
    "                                              criterion='gini',\n",
    "                                              max_depth=6,\n",
    "                                              min_samples_leaf=2,\n",
    "                                              min_samples_split=2)))\n",
    "level0.append(('bayes', GaussianNB(var_smoothing=1e-3)))\n",
    "level0.append(('knn', KNeighborsClassifier(algorithm='brute', metric='manhattan', n_jobs=-1)))\n",
    "level1 = XGBClassifier(max_depth=6, n_estimators=100)\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "# Accuracy: 0.7098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X_test)\n",
    "# accuracy: 0.7907142857142857\n",
    "#  precision: 0.7767078326068108\n",
    "#  recall: 0.7925641755133975\n",
    "#  f1: 0.7832001781704138\n",
    "#  ROC AUC: 0.9187760308862817\n",
    "\n",
    "# Class 0:\n",
    "# Precision: 0.759\n",
    "# Recall: 0.858\n",
    "# F1 score: 0.805\n",
    "# ROC AUC: 0.931\n",
    "# Gini coefficient: 0.747\n",
    "\n",
    "# Class 1:\n",
    "# Precision: 0.830\n",
    "# Recall: 0.767\n",
    "# F1 score: 0.797\n",
    "# ROC AUC: 0.852\n",
    "# Gini coefficient: 0.589\n",
    "\n",
    "# Class 2:\n",
    "# Precision: 0.741\n",
    "# Recall: 0.753\n",
    "# F1 score: 0.747\n",
    "# ROC AUC: 0.952\n",
    "# Gini coefficient: 0.696"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
