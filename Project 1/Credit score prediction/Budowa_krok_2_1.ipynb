{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nse1jbiOpp7t"
   },
   "source": [
    "# IMPORTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hO6AKocPHdk4"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datetime import datetime\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "np.random.seed(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo-e4O-CTtgu"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zZeHMyq1rzs"
   },
   "outputs": [],
   "source": [
    "# Wczytanie Danych\n",
    "df = pd.read_csv('train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKG0sXkAXNfb"
   },
   "source": [
    "Cały preprocessing z poprzednich kamieni milowych sprowadziliśmy do pojedynczej funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MT9TZstqkscP"
   },
   "outputs": [],
   "source": [
    "# Funkcje pomocnicze\n",
    "def zamiana_typów_kolumn_na_numeryczne(df):\n",
    "    df['Outstanding_Debt'] = Object_to_Numeric(df, 'Outstanding_Debt')\n",
    "    df['Amount_invested_monthly'] = Object_to_Numeric(df, 'Amount_invested_monthly')\n",
    "    df['Changed_Credit_Limit'] = Object_to_Numeric(df, 'Changed_Credit_Limit')\n",
    "    df['Monthly_Balance'] = df['Monthly_Balance'].str.replace('_', '')\n",
    "    df = df.astype({'Monthly_Balance': 'float'})\n",
    "    df['Credit_History_Age'] = History_Age_2_months(df)\n",
    "    df['Credit_History_Age'].loc[df.Credit_History_Age.isnull()] = df['Credit_History_Age'].loc[df.Credit_History_Age.isnull()].apply(\n",
    "          lambda x: '-1') #Brak danych jest teraz -1 \n",
    "    df['Credit_History_Age'] = df['Credit_History_Age'].apply(eval)\n",
    "    df['Payment_Behaviour'] = np.where(df['Payment_Behaviour']== '!@9#%8', np.nan, df['Payment_Behaviour'])\n",
    "    df['spent'] = np.where('Low' == df['Payment_Behaviour'].str[0:3], 0,1)\n",
    "    #2 Month na numeric\n",
    "    df['Month'] = df['Month'].apply(lambda mname: datetime.strptime(mname, '%B').month)\n",
    "\n",
    "    #4 Age na numeric\n",
    "    df['Age'] = df['Age'].convert_dtypes().apply(lambda x: x.replace(\"_\", \"\")).astype(int)\n",
    "\n",
    "    #7 Annual_Income na numeric\n",
    "    df['Annual_Income'] = df['Annual_Income'].convert_dtypes().apply(lambda x: x.replace(\"_\", \"\")).astype(float)\n",
    "\n",
    "    #12 Num_of_Loan na numeric\n",
    "    df['Num_of_Loan'] = df['Num_of_Loan'].convert_dtypes().apply(lambda x: x.replace(\"_\", \"\")).astype(int)\n",
    "\n",
    "    #15 Num_of_Delayed_Payment na numeric\n",
    "    df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].convert_dtypes()\n",
    "    df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].str.replace('_', '')\n",
    "    df['Num_of_Delayed_Payment'] = pd.to_numeric(df['Num_of_Delayed_Payment'])\n",
    "\n",
    "    df['payment_value'] = df['Payment_Behaviour'].str.extract(r'^(?:[^_]+_){2}([^_ ]+)')\n",
    "    df['payment_value'] = df['payment_value'].replace('Small', 0)\n",
    "    df['payment_value'] = df['payment_value'].replace('Medium', 1)\n",
    "    df['payment_value'] = df['payment_value'].replace('Large', 2)\n",
    "\n",
    "    df = df.drop('Payment_Behaviour', axis=1)\n",
    "\n",
    "    # __ część z one_hot ___\n",
    "    # Type_of_Loan\n",
    "    df['Type_of_Loan'] = df['Type_of_Loan'].str.replace('and ', '')\n",
    "    df.Type_of_Loan = df.Type_of_Loan.str.split(', ')\n",
    "    df['Type_of_Loan'].loc[df.Type_of_Loan.isnull()] = df['Type_of_Loan'].loc[df.Type_of_Loan.isnull()].apply(lambda x: [])\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    df = df.join(\n",
    "        pd.DataFrame.sparse.from_spmatrix(\n",
    "            mlb.fit_transform(df.pop('Type_of_Loan')),\n",
    "            index=df.index,\n",
    "            columns=mlb.classes_))\n",
    "    \n",
    "    # Credit_Mix i Occupation\n",
    "    one_hot_encoded = pd.get_dummies(df['Credit_Mix'], prefix='Credit_Mix')\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "    one_hot_encoded = pd.get_dummies(df['Occupation'], prefix='Occupation')\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "    #Payment_of_Min_Amount\n",
    "    grouped = df.groupby('Customer_ID', group_keys=False)\n",
    "    df[['Payment_of_Min_Amount']] = grouped[['Payment_of_Min_Amount']].apply(lambda x: x.fillna(x.mode()))\n",
    "    df['Payment_of_Min_Amount'].fillna(df['Payment_of_Min_Amount'].mode()[0])\n",
    "    one_hot_encoded = pd.get_dummies(df['Payment_of_Min_Amount'], prefix='Payment_of_Min_Amount')\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "    \n",
    "    df.drop(columns=['ID','SSN','Name'], inplace=True) #SSN to be removed\n",
    "    df.drop(columns=['Payment_of_Min_Amount', 'Credit_Mix', 'Occupation', 'Payment_of_Min_Amount'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0jHs4mbmZ1P"
   },
   "outputs": [],
   "source": [
    "def History_Age_2_months(df):\n",
    "      df['Credit_History_Age'] = df['Credit_History_Age'].str.replace(' Months', '')\n",
    "      return df['Credit_History_Age'].str.replace('\\D+', '* 12 +')\n",
    "\n",
    "def Object_to_Numeric(df, s):\n",
    "    return pd.to_numeric(df[s].str.replace('_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t86v8-BfHK6O"
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "\n",
    "  def Zamiana_nan_na_medianę_modę(df):\n",
    "\n",
    "    # Zamiana na NaN, a nie usunięcie rekordu\n",
    "    df.Monthly_Balance = np.where(df.Monthly_Balance == min(df.Monthly_Balance), np.nan, df.Monthly_Balance)\n",
    "    grouped = df.groupby('Customer_ID', group_keys=False)\n",
    "\n",
    "    # Zamiana NaN na medianę dla danej grupy (Grupa = zbiór rekordów danego użytkownika, identyfikowany przez jego SSN)\n",
    "    df[['Monthly_Inhand_Salary']] = grouped[['Monthly_Inhand_Salary']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Num_Bank_Accounts']] = grouped[['Num_Bank_Accounts']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Num_of_Delayed_Payment']] = grouped[['Num_of_Delayed_Payment']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Changed_Credit_Limit']] = grouped[['Changed_Credit_Limit']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Num_Credit_Inquiries']] = grouped[['Num_Credit_Inquiries']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Monthly_Balance']] = grouped[['Monthly_Balance']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['Amount_invested_monthly']] = grouped[['Amount_invested_monthly']].apply(lambda x: x.fillna(x.median()))\n",
    "    df[['payment_value']] = grouped[['payment_value']].apply(lambda x: x.fillna(x.mode()))\n",
    "\n",
    "    df['Num_Bank_Accounts'].fillna(df['Num_Bank_Accounts'].median(), inplace=True) \n",
    "    df['Num_of_Delayed_Payment'].fillna(df['Num_of_Delayed_Payment'].median(), inplace=True) \n",
    "    df['Num_Bank_Accounts'].fillna(df['Num_Bank_Accounts'].median(), inplace=True) \n",
    "    df['Changed_Credit_Limit'].fillna(df['Changed_Credit_Limit'].median(), inplace=True) \n",
    "    df['Num_Credit_Inquiries'].fillna(df['Num_Credit_Inquiries'].median(), inplace=True) \n",
    "    df['Monthly_Inhand_Salary'].fillna(df['Monthly_Inhand_Salary'].median(), inplace=True) \n",
    "    df['Monthly_Balance'].fillna(df['Monthly_Balance'].median(), inplace=True) \n",
    "    df['payment_value'].fillna(df['payment_value'].mode()[0], inplace=True) \n",
    "    df['Amount_invested_monthly'].fillna(df['Amount_invested_monthly'].median(), inplace=True)\n",
    "    return df\n",
    "  \n",
    "  df = zamiana_typów_kolumn_na_numeryczne(df)\n",
    "  df = Zamiana_nan_na_medianę_modę(df)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9myvyx628Lv"
   },
   "outputs": [],
   "source": [
    "X_TRAIN, X_valid = train_test_split(df, test_size=0.30, random_state=42)\n",
    "y_test = X_test['Credit_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZLkzWcV3CEJ"
   },
   "outputs": [],
   "source": [
    "target = X_TRAIN['Credit_Score']\n",
    "X_train, X_test=train_test_split(\n",
    "    X_TRAIN, # X\n",
    "    test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDB0HA5pMx_X",
    "outputId": "33553407-6b41-4277-875d-119daa37c7a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-c974350e5715>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return df['Credit_History_Age'].str.replace('\\D+', '* 12 +')\n",
      "<ipython-input-84-c974350e5715>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Credit_History_Age'].loc[df.Credit_History_Age.isnull()] = df['Credit_History_Age'].loc[df.Credit_History_Age.isnull()].apply(\n",
      "<ipython-input-84-c974350e5715>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Type_of_Loan'].loc[df.Type_of_Loan.isnull()] = df['Type_of_Loan'].loc[df.Type_of_Loan.isnull()].apply(lambda x: [])\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1ho43-skxyz",
    "outputId": "c81d0f19-ff6a-4a2c-dd4c-19908e345197"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-6824ee280100>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return df['Credit_History_Age'].str.replace('\\D+', '* 12 +')\n",
      "<ipython-input-8-f0c825b1f133>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Credit_History_Age'].loc[df.Credit_History_Age.isnull()] = df['Credit_History_Age'].loc[df.Credit_History_Age.isnull()].apply(\n",
      "<ipython-input-8-f0c825b1f133>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Type_of_Loan'].loc[df.Type_of_Loan.isnull()] = df['Type_of_Loan'].loc[df.Type_of_Loan.isnull()].apply(lambda x: [])\n"
     ]
    }
   ],
   "source": [
    "X_test = zamiana_typów_kolumn_na_numeryczne(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ftn7HCDU2Qf"
   },
   "outputs": [],
   "source": [
    "grouped = X_train.groupby('Customer_ID', group_keys=False)\n",
    "grouped2 = X_test.groupby('Customer_ID', group_keys=False)\n",
    "\n",
    "col_names = ['Monthly_Inhand_Salary','Num_Bank_Accounts','Num_of_Delayed_Payment','Changed_Credit_Limit','Num_Credit_Inquiries','Monthly_Balance',\n",
    "             'Amount_invested_monthly']\n",
    "\n",
    "for col_name in col_names:\n",
    "  new_table = np.array([]) \n",
    "  for key, item in grouped2:\n",
    "    if key in grouped.groups.keys():\n",
    "      if not math.isnan(grouped[[col_name]].get_group(key).median()[0]):\n",
    "        item[col_name].fillna(grouped[[col_name]].get_group(key).median()[0], inplace=True)\n",
    "        item1 = item.copy()\n",
    "        if new_table.shape[0]==0:\n",
    "            new_table = item1\n",
    "        else:\n",
    "            new_table = pd.concat([new_table,item1])\n",
    "      else:\n",
    "        item.fillna(X_train[col_name].median(), inplace=True)\n",
    "        item1 = item.copy()\n",
    "        if new_table.shape[0]==0:\n",
    "            new_table = item1\n",
    "        else:\n",
    "            new_table = pd.concat([new_table,item1])\n",
    "    else:\n",
    "      item.fillna(X_train[col_name].median(), inplace=True)\n",
    "      item1 = item.copy()\n",
    "      if new_table.shape[0]==0:\n",
    "          new_table = item1\n",
    "      else:\n",
    "          new_table = pd.concat([new_table,item1])\n",
    "  temp = new_table.copy()\n",
    "  X_train[col_name] = temp[col_name]\n",
    "\n",
    "\n",
    "new_table = np.array([]) \n",
    "for key, item in grouped2:\n",
    "  if key in grouped.groups.keys():\n",
    "    if not math.isnan(grouped[['payment_value']].get_group(key).mode()[0]):\n",
    "      item['payment_value'].fillna(grouped[['payment_value']].get_group(key).mode()[0], inplace=True)\n",
    "      item1 = item.copy()\n",
    "      if new_table.shape[0]==0:\n",
    "          new_table = item1\n",
    "      else:\n",
    "          new_table = pd.concat([new_table,item1])\n",
    "    else:\n",
    "      item.fillna(X_train['payment_value'].mode(), inplace=True)\n",
    "      item1 = item.copy()\n",
    "      if new_table.shape[0]==0:\n",
    "          new_table = item1\n",
    "      else:\n",
    "          new_table = pd.concat([new_table,item1])\n",
    "  else:\n",
    "    item.fillna(X_train['payment_value'].mode(), inplace=True)\n",
    "    item1 = item.copy()\n",
    "    if new_table.shape[0]==0:\n",
    "        new_table = item1\n",
    "    else:\n",
    "        new_table = pd.concat([new_table,item1])\n",
    "X_train['payment_value'] = temp['payment_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kl0XbPaskckf"
   },
   "outputs": [],
   "source": [
    "y_test = X_test['Credit_Score']\n",
    "X_test.drop(columns=['Credit_Score', 'Customer_ID'], inplace=True)\n",
    "\n",
    "y_train = X_train['Credit_Score']\n",
    "X_train.drop(columns=['Credit_Score', 'Customer_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25KUwlX-VbBP"
   },
   "source": [
    "# Minmax Scaler i Outliery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j8MZkbZWmtC"
   },
   "source": [
    "Każda kolumna traktowana oddzielnie, jednak poziom odcięcia zbioru testowego bezpośrednio przenoszona jest ze zbioru treningowego, podobnie jak wartości minimalne/maksymalne przy minmax scalerze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sdw2E3JrO5Tt"
   },
   "outputs": [],
   "source": [
    "# Definiujemy nasz własny min_max scaler, by wartości min/max pochodziły ze\n",
    "# zbioru treningowego.\n",
    "def scale_mm(x_train, x_test):\n",
    "  x_train_std = (x_train - x_train.min(axis=0)) / (x_train.max(axis=0) - x_train.min(axis=0))\n",
    "  x_test_std = (x_test - x_train.min(axis=0)) / (x_train.max(axis=0) - x_train.min(axis=0))\n",
    "  return x_train_std, x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOCnhiHsN3KA"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Annual_Income.quantile(.99)\n",
    "\n",
    "X_train.Annual_Income = np.where(X_train.Annual_Income > upper_lim, upper_lim, X_train.Annual_Income)\n",
    "X_test.Annual_Income = np.where(X_test.Annual_Income > upper_lim, upper_lim, X_test.Annual_Income)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6HsJKFROn3P"
   },
   "outputs": [],
   "source": [
    "X_train.Annual_Income, X_test.Annual_Income = scale_mm(X_train.Annual_Income, X_test.Annual_Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0X5D0pfDQJgT"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Amount_invested_monthly.quantile(.98)\n",
    "\n",
    "X_train.Amount_invested_monthly = np.where(X_train.Amount_invested_monthly > upper_lim, upper_lim, X_train.Amount_invested_monthly)\n",
    "X_test.Amount_invested_monthly = np.where(X_test.Amount_invested_monthly > upper_lim, upper_lim, X_test.Amount_invested_monthly)\n",
    "\n",
    "X_train.Amount_invested_monthly = np.log1p(X_train.Amount_invested_monthly)\n",
    "X_test.Amount_invested_monthly = np.log1p(X_test.Amount_invested_monthly)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNzHy9_sQi6m"
   },
   "outputs": [],
   "source": [
    "X_train.Amount_invested_monthly, X_test.Amount_invested_monthly = scale_mm(X_train.Amount_invested_monthly, X_test.Amount_invested_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bKX0leLS3Hm"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Total_EMI_per_month.quantile(.96)\n",
    "\n",
    "X_train.Total_EMI_per_month = np.where(X_train.Total_EMI_per_month > upper_lim, upper_lim, X_train.Total_EMI_per_month)\n",
    "X_test.Total_EMI_per_month = np.where(X_test.Total_EMI_per_month > upper_lim, upper_lim, X_test.Total_EMI_per_month)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "X_train.Total_EMI_per_month = np.log1p(X_train.Total_EMI_per_month)\n",
    "X_test.Total_EMI_per_month = np.log1p(X_test.Total_EMI_per_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdHPv8-2TF6O"
   },
   "outputs": [],
   "source": [
    "X_train.Credit_Utilization_Ratio, X_test.Credit_Utilization_Ratio = scale_mm(X_train.Credit_Utilization_Ratio, X_test.Credit_Utilization_Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD6PRslvTNNJ"
   },
   "outputs": [],
   "source": [
    "X_train.Outstanding_Debt, X_test.Outstanding_Debt = scale_mm(X_train.Outstanding_Debt, X_test.Outstanding_Debt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8fbQDPbTV0K"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_Credit_Inquiries.quantile(.96)\n",
    "\n",
    "X_train.Num_Credit_Inquiries = np.where(X_train.Num_Credit_Inquiries > upper_lim, upper_lim, X_train.Num_Credit_Inquiries)\n",
    "X_test.Num_Credit_Inquiries = np.where(X_test.Num_Credit_Inquiries > upper_lim, upper_lim, X_test.Num_Credit_Inquiries)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkkvneblTf5T"
   },
   "outputs": [],
   "source": [
    "X_train.Changed_Credit_Limit, X_test.Changed_Credit_Limit = scale_mm(X_train.Changed_Credit_Limit, X_test.Changed_Credit_Limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDOgsFLLTqLD"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Age.quantile(.98)\n",
    "lower_lim = X_train.Age.quantile(.05)\n",
    "\n",
    "X_train.Age = np.where(X_train.Age > upper_lim, upper_lim, X_train.Age)\n",
    "X_test.Age = np.where(X_test.Age > upper_lim, upper_lim, X_test.Age)\n",
    "\n",
    "X_train.Age = np.where(X_train.Age < lower_lim, lower_lim, X_train.Age)\n",
    "X_test.Age = np.where(X_test.Age < lower_lim, lower_lim, X_test.Age)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7mKYbaZUDXT"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_Bank_Accounts.quantile(.98)\n",
    "lower_lim = X_train.Num_Bank_Accounts.quantile(.00)\n",
    "\n",
    "X_train.Num_Bank_Accounts = np.where(X_train.Num_Bank_Accounts > upper_lim, upper_lim, X_train.Num_Bank_Accounts)\n",
    "X_test.Num_Bank_Accounts = np.where(X_test.Num_Bank_Accounts > upper_lim, upper_lim, X_test.Num_Bank_Accounts)\n",
    "\n",
    "X_train.Num_Bank_Accounts = np.where(X_train.Num_Bank_Accounts < lower_lim, lower_lim, X_train.Num_Bank_Accounts)\n",
    "X_test.Num_Bank_Accounts = np.where(X_test.Num_Bank_Accounts < lower_lim, lower_lim, X_test.Num_Bank_Accounts)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsWKMO64UQM4"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_Credit_Card.quantile(.97)\n",
    "lower_lim = X_train.Num_Credit_Card.quantile(.00)\n",
    "\n",
    "X_train.Num_Credit_Card = np.where(X_train.Num_Credit_Card > upper_lim, upper_lim, X_train.Num_Credit_Card)\n",
    "X_test.Num_Credit_Card = np.where(X_test.Num_Credit_Card > upper_lim, upper_lim, X_test.Num_Credit_Card)\n",
    "\n",
    "X_train.Num_Credit_Card = np.where(X_train.Num_Credit_Card < lower_lim, lower_lim, X_train.Num_Credit_Card)\n",
    "X_test.Num_Credit_Card = np.where(X_test.Num_Credit_Card < lower_lim, lower_lim, X_test.Num_Credit_Card)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5nh7F5LUaCl"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Interest_Rate.quantile(.97)\n",
    "\n",
    "X_train.Interest_Rate = np.where(X_train.Interest_Rate > upper_lim, upper_lim, X_train.Interest_Rate)\n",
    "X_test.Interest_Rate = np.where(X_test.Interest_Rate > upper_lim, upper_lim, X_test.Interest_Rate)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxqrjkUHUhBy"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_of_Loan.quantile(.99)\n",
    "lower_lim = X_train.Num_of_Loan.quantile(.04)\n",
    "X_train.Num_of_Loan = np.where(X_train.Num_of_Loan > upper_lim, upper_lim, X_train.Num_of_Loan)\n",
    "X_test.Num_of_Loan = np.where(X_test.Num_of_Loan > upper_lim, upper_lim, X_test.Num_of_Loan)\n",
    "\n",
    "X_train.Num_of_Loan = np.where(X_train.Num_of_Loan < lower_lim, lower_lim, X_train.Num_of_Loan)\n",
    "X_test.Num_of_Loan = np.where(X_test.Num_of_Loan < lower_lim, lower_lim, X_test.Num_of_Loan)\n",
    "\n",
    "X_train =X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jE1OPMrvUtaX"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Delay_from_due_date.quantile(.99)\n",
    "\n",
    "X_train.Delay_from_due_date = np.where(X_train.Delay_from_due_date > upper_lim, upper_lim, X_train.Delay_from_due_date)\n",
    "X_test.Delay_from_due_date = np.where(X_test.Delay_from_due_date > upper_lim, upper_lim, X_test.Delay_from_due_date)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxpZBYaIUz7t"
   },
   "outputs": [],
   "source": [
    "upper_lim = X_train.Num_of_Delayed_Payment.quantile(.99)\n",
    "lower_lim = X_train.Num_of_Delayed_Payment.quantile(.01)\n",
    "\n",
    "X_train.Num_of_Delayed_Payment = np.where(X_train.Num_of_Delayed_Payment > upper_lim, upper_lim, X_train.Num_of_Delayed_Payment)\n",
    "X_test.Num_of_Delayed_Payment = np.where(X_test.Num_of_Delayed_Payment > upper_lim, upper_lim, X_test.Num_of_Delayed_Payment)\n",
    "\n",
    "X_train.Num_of_Delayed_Payment = np.where(X_train.Num_of_Delayed_Payment < lower_lim, upper_lim, X_train.Num_of_Delayed_Payment)\n",
    "X_test.Num_of_Delayed_Payment = np.where(X_test.Num_of_Delayed_Payment < lower_lim, upper_lim, X_test.Num_of_Delayed_Payment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZOnBn7xVFzf"
   },
   "outputs": [],
   "source": [
    "# Usunięcie kolumn na podstawie korelacji spearmana (>90)\n",
    "X_train = X_train.drop(columns=['Monthly_Inhand_Salary', 'Month'])\n",
    "X_test = X_test.drop(columns=['Monthly_Inhand_Salary', 'Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uj6emXN9V5L5"
   },
   "outputs": [],
   "source": [
    "y_test = y_test.replace('Good', 2)\n",
    "y_test = y_test.replace('Standard', 1)\n",
    "y_test = y_test.replace('Poor', 0)\n",
    "\n",
    "y_train = y_train.replace('Good', 2)\n",
    "y_train = y_train.replace('Standard', 1)\n",
    "y_train = y_train.replace('Poor', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hybNOTKUl3XE"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpUqtv98WOC7"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f4dXlejbb_6"
   },
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    \n",
    "    models = dict()\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=1000, # Ilość słabych estymatorów\n",
    "                                      max_depth=2, # Maksymalna wysokość drzewa w słabym estymatorze\n",
    "                                      min_samples_split = 2, # Minimalna ilość obserwacji wymagana do podziału węzła\n",
    "                                      max_features = 3, # Maksymalna ilość zmiennych brana pod uwagę przy podziale węzła\n",
    "                                      random_state=0,\n",
    "                                      n_jobs = -1)\n",
    "    \n",
    "    models['aboost'] = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "    models['gboost'] = GradientBoostingClassifier(random_state=1,\n",
    "                                      learning_rate=0.01)\n",
    "    \n",
    "    models['xgb'] = XGBClassifier(random_state=1,\n",
    "                        learning_rate=0.01, # Szybkość \"uczenia\" się\n",
    "                        booster='gbtree', # Jaki model wykorzystujemy (drzewo - gbtree, liniowe - gblinear)\n",
    "                        max_depth=4 # Maksymalna głębokość drzewa \n",
    "                        )\n",
    "    \n",
    "    models['svm'] = SVC()\n",
    "\n",
    "    models['bayes'] = GaussianNB()\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6vGOoPfb2Rz"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP9NvUENb3iI"
   },
   "outputs": [],
   "source": [
    "# modele do evaluacji\n",
    "models = get_models()\n",
    "# ocena modeli\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X_train, y_train)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('%8s mean-%.3f std-%.3f' % (name, np.mean(scores), np.std(scores)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
